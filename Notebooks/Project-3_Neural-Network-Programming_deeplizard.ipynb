{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model part 2 - loss, gradient, backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's move on to actually training data. \n",
    "\n",
    "# The training process:\n",
    "# 1) Get batch from training set\n",
    "# 2) Pass batch to network\n",
    "# 3) Calculate the loss\n",
    "# 4) Get the gradient of loss vs network weights\n",
    "# 5) Update the weights according to this gradient to reduce loss. \n",
    "\n",
    "# 6) Repeat 1-5 for one epoch (one pass through full training set)\n",
    "# 7) Complete 1-6 for appropriate number of epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x121405e10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We already know steps 1 and 2. What about the loss function? \n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import torchvision # computer vision package \n",
    "import torchvision.transforms as transforms # interface for common IP transforms. \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms \n",
    "torch.set_printoptions(linewidth=120)\n",
    "torch.set_grad_enabled(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# alright. Back to implementing the network. \n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 6, kernel_size = 5)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 6, out_channels = 12, kernel_size = 5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features = 12*4*4, out_features = 120) # \"fully connected\". Also, \"dense\"\n",
    "        self.fc2 = nn.Linear(in_features = 120, out_features = 60)\n",
    "        self.out = nn.Linear(in_features = 60, out_features = 10)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        # time to actually implement forward, layer by layer\n",
    "        # 1) input layer\n",
    "        t = t\n",
    "        \n",
    "        # 2) conv1 - 3 operations. Convolution, activation, and pooling. \n",
    "        t = self.conv1(t) # that easy - we just call the layer obejct on our input! Neat. \n",
    "        t = F.relu(t) # activation function\n",
    "        t = F.max_pool2d(t, kernel_size = 2, stride = 2) # pool the convolution output \n",
    "        \n",
    "        # 3) conv2\n",
    "        t = self.conv2(t) # that easy - we just call the layer obejct on our input! Neat. \n",
    "        t = F.relu(t) \n",
    "        t = F.max_pool2d(t, kernel_size = 2, stride = 2)\n",
    "        \n",
    "        # 4) fc1\n",
    "        t = t.reshape(-1, 12 * 4 * 4) # when we swap from conv to linear, we need to reshape\n",
    "        # 12 is number of output channels from previous layer\n",
    "        # 4x4 is height and with of each of the channels, determined by previous pooling operations. \n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # 5) fc2\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "\n",
    "        # 6) out \n",
    "        t = self.out(t)\n",
    "#         t.softmax(t, dim=1) # change to percentages. Different activation function\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum() # number of correct guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LOAD\n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root = './data/FashionMNIST',\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = transforms.Compose([ # This is the transform. Easy. \n",
    "        transforms.ToTensor() # TRANSFORM\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "images, labels = batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network()\n",
    "preds = network(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = F.cross_entropy(preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3082938194274902"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item() # summed differences of predictions from labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0) cl: 8.872130393981934\n",
      "10) cl: 0.12297342717647552\n",
      "20) cl: 2.8746678829193115\n",
      "30) cl: 4.868659973144531\n",
      "40) cl: 5.863234043121338\n",
      "50) cl: 2.876112937927246\n",
      "60) cl: 4.870473384857178\n",
      "70) cl: 2.8767216205596924\n",
      "80) cl: 0.8737058043479919\n",
      "90) cl: 8.871868133544922\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(preds)):\n",
    "    loss_i = abs(preds[i].max().item() - labels[i])\n",
    "    if i%10==0:\n",
    "        print(\"{}) cl: {}\".format(i, loss_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# we have our loss. Now, what about gradients?\n",
    "print(network.conv1.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-1.0213e-03, -6.0217e-04, -3.5090e-04, -6.6514e-04, -1.6521e-03],\n",
      "          [-6.5744e-04, -3.2261e-04, -3.8479e-04, -7.4669e-04, -1.7587e-03],\n",
      "          [-7.6745e-04, -3.9491e-04, -4.6891e-04, -1.0875e-03, -1.7523e-03],\n",
      "          [-8.4279e-04, -4.1597e-04, -2.8424e-04, -1.0495e-03, -1.8093e-03],\n",
      "          [-3.8704e-04, -5.6582e-04, -6.3969e-04, -1.5271e-03, -1.8251e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.5149e-04, -3.5799e-05,  5.0507e-06, -4.1301e-06,  8.2016e-07],\n",
      "          [-2.0818e-04,  7.2200e-06, -2.9325e-06, -6.7616e-06,  2.4076e-06],\n",
      "          [-1.5251e-04,  1.3392e-06, -5.3205e-06, -1.1740e-05,  1.5879e-05],\n",
      "          [-1.4451e-04, -4.7039e-06,  4.7099e-06,  3.9046e-05, -1.1307e-04],\n",
      "          [-7.1386e-05,  1.0393e-05,  2.0262e-05, -3.8235e-05, -4.3980e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1552e-03,  2.9186e-04, -4.0394e-04, -2.4013e-04, -6.2014e-04],\n",
      "          [ 8.4670e-04,  4.1739e-04, -3.2125e-04, -5.0695e-04, -5.2845e-04],\n",
      "          [ 8.3865e-04,  4.0994e-04, -6.7180e-05, -7.4328e-04, -6.4395e-04],\n",
      "          [ 7.1835e-04,  3.0377e-04, -4.7847e-04, -1.0449e-03, -9.7537e-04],\n",
      "          [ 6.3684e-04,  2.8961e-04, -1.4614e-04, -4.9833e-04, -3.9612e-04]]],\n",
      "\n",
      "\n",
      "        [[[-1.1466e-03, -1.6063e-03, -9.6183e-04, -1.0512e-03, -8.0012e-04],\n",
      "          [-8.8428e-04, -1.0312e-03, -4.3421e-04, -5.8017e-04, -1.7725e-04],\n",
      "          [-5.1873e-04, -4.2484e-04, -1.7345e-04, -2.4630e-04, -2.2364e-04],\n",
      "          [-2.6399e-04, -2.4210e-04, -1.5313e-04, -4.7003e-04, -3.9259e-04],\n",
      "          [-4.9983e-04, -2.9800e-04, -3.2614e-04, -3.4646e-04, -3.5304e-04]]],\n",
      "\n",
      "\n",
      "        [[[-1.7336e-03, -1.8087e-03, -1.1233e-03, -3.0626e-04,  2.9020e-04],\n",
      "          [-1.8277e-03, -2.1587e-03, -1.3235e-03, -3.5288e-04,  4.6005e-04],\n",
      "          [-1.7326e-03, -1.8378e-03, -1.3486e-03, -2.5533e-04,  4.5392e-04],\n",
      "          [-1.7823e-03, -1.7867e-03, -1.1897e-03, -4.0399e-04,  3.9973e-04],\n",
      "          [-1.8092e-03, -1.9503e-03, -1.1083e-03, -7.0420e-04,  1.5267e-04]]],\n",
      "\n",
      "\n",
      "        [[[-2.6002e-04, -1.6291e-04,  1.0037e-04,  2.2196e-04,  3.1543e-04],\n",
      "          [-4.1467e-04, -6.3456e-04, -3.4271e-04,  1.3485e-04, -2.7440e-04],\n",
      "          [-4.4396e-04, -7.4314e-04, -2.8346e-04, -2.4245e-04, -2.2706e-04],\n",
      "          [-3.1603e-04, -6.5298e-04, -2.1662e-04,  1.8484e-04, -6.3802e-04],\n",
      "          [-8.2698e-04, -8.7707e-04, -3.8765e-04, -2.8384e-04, -1.2661e-03]]]])\n"
     ]
    }
   ],
   "source": [
    "print(network.conv1.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Nice backprop is done, and gradients for each weight tensor in the grad attribute have been updated\n",
    "# step 4 done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update The Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update weights according to gradients\n",
    "# we need an optimizer to do this. \n",
    "optimizer = optim.Adam(network.parameters(), lr=.01) # need to pass the actual weights we want updated. \n",
    "# these weights live in the network's parameters instance. \n",
    "# lr is the learning rate. Dictates the size of the \"leap\" each learning step takes \n",
    "\n",
    "get_num_correct(preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer.step() # take a step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = network(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_num_correct(preds, labels)\n",
    "loss = F.cross_entropy(preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2794179916381836"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()\n",
    "optimizer.step()\n",
    "preds = network(images)\n",
    "loss = F.cross_entropy(preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.234861373901367"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item() # bada bing bada boom. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_num_correct(preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:50\n",
      "\t\tloss: 2.303581476211548\n",
      "\t\tnum_correct: 11\n",
      "i:100\n",
      "\t\tloss: 2.2861835956573486\n",
      "\t\tnum_correct: 11\n",
      "i:150\n",
      "\t\tloss: 2.261082410812378\n",
      "\t\tnum_correct: 12\n",
      "i:200\n",
      "\t\tloss: 2.2494986057281494\n",
      "\t\tnum_correct: 12\n",
      "i:250\n",
      "\t\tloss: 2.198390483856201\n",
      "\t\tnum_correct: 16\n",
      "i:300\n",
      "\t\tloss: 2.1417696475982666\n",
      "\t\tnum_correct: 21\n",
      "i:350\n",
      "\t\tloss: 2.114436388015747\n",
      "\t\tnum_correct: 33\n",
      "i:400\n",
      "\t\tloss: 2.068920373916626\n",
      "\t\tnum_correct: 37\n",
      "i:450\n",
      "\t\tloss: 1.9670729637145996\n",
      "\t\tnum_correct: 36\n",
      "i:500\n",
      "\t\tloss: 1.8496395349502563\n",
      "\t\tnum_correct: 29\n"
     ]
    }
   ],
   "source": [
    "# now in a loop. \n",
    "i = 0\n",
    "network = Network()\n",
    "optimizer = optim.Adam(network.parameters(), lr=.01) # need to pass the actual weights we want updated. \n",
    "\n",
    "preds = network(images)\n",
    "loss = F.cross_entropy(preds, labels)\n",
    "\n",
    "while i < 500:\n",
    "    i+=1\n",
    "    if i%50==0:\n",
    "        preds = network(images)\n",
    "        loss = F.cross_entropy(preds, labels)\n",
    "        print(\"i:{}\\n\\t\\tloss: {}\".format(i, loss.item()))\n",
    "        print(\"\\t\\tnum_correct: {}\".format(get_num_correct(preds, labels)))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "# here, we jump over a local minimum a few times. check out how num_correct goes up and down\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's try it with a bunch of different batches - this is what is actually relevant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epoch Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 total_correct: tensor(47745) loss: 324.13429021835327\n"
     ]
    }
   ],
   "source": [
    "network = Network()\n",
    "optimizer = optim.Adam(network.parameters(), lr=.01) # need to pass the actual weights we want updated. \n",
    "\n",
    "total_loss = 0\n",
    "total_correct = 0\n",
    "\n",
    "for batch in train_loader:\n",
    "    images, labels = batch\n",
    "    preds = network(images)\n",
    "    loss = F.cross_entropy(preds, labels)\n",
    "\n",
    "    total_loss += loss.item()\n",
    "    total_correct += get_num_correct(preds, labels)\n",
    "    \n",
    "    optimizer.zero_grad() # clean up the gradients before calculating new ones with each step\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "print(\"epoch:\", 0, \"total_correct:\", total_correct, \"loss:\", total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79575"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_correct.item()/len(train_set) # not bad, not bad at all\n",
    "# changing the batch size means that we change the number of steps we can take via the learning step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 total_correct: tensor(47674) loss: 328.8852970302105\n",
      "epoch: 2 total_correct: tensor(99411) loss: 552.2759694308043\n",
      "epoch: 3 total_correct: tensor(151874) loss: 759.0829255878925\n",
      "epoch: 4 total_correct: tensor(204490) loss: 959.0505998879671\n",
      "epoch: 5 total_correct: tensor(257420) loss: 1151.7279862314463\n",
      "0.8580666666666666\n"
     ]
    }
   ],
   "source": [
    "network = Network()\n",
    "optimizer = optim.Adam(network.parameters(), lr=.01) # need to pass the actual weights we want updated. \n",
    "\n",
    "total_loss = 0\n",
    "total_correct = 0\n",
    "epoch = 0\n",
    "\n",
    "while epoch < 5:\n",
    "    for batch in train_loader:\n",
    "        images, labels = batch\n",
    "        preds = network(images)\n",
    "        loss = F.cross_entropy(preds, labels)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_correct += get_num_correct(preds, labels)\n",
    "\n",
    "        optimizer.zero_grad() # clean up the gradients before calculating new ones with each step\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    epoch += 1\n",
    "    print(\"epoch:\", epoch, \"total_correct:\", total_correct, \"loss:\", total_loss)\n",
    "    \n",
    "print(total_correct.item()/(epoch*len(train_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 86% accuracy after 5 epochs. Pretty good. \n",
    "\n",
    "# Now on to the confusion matrix. \n",
    "\n",
    "len(train_set)\n",
    "len(train_set.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 60,000 images and 60,000 labels \n",
    "\n",
    "def get_all_preds(model, loader):\n",
    "    all_preds = torch.tensor([])\n",
    "    for batch in loader:\n",
    "            images, labels = batch\n",
    "            preds = model(images)\n",
    "            \n",
    "            all_preds = torch.cat((all_preds, preds), dim=0)\n",
    "            \n",
    "    return all_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_loader = torch.utils.data.DataLoader(train_set, batch_size = 10000)\n",
    "train_preds = get_all_preds(network, prediction_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 10])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preds.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexquill/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train_preds.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CatBackward at 0x12417f908>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preds.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    prediction_loader = torch.utils.data.DataLoader(train_set, batch_size = 10000)\n",
    "    train_preds = get_all_preds(network, prediction_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88245\n"
     ]
    }
   ],
   "source": [
    "preds_correct = get_num_correct(train_preds, train_set.targets)\n",
    "print(preds_correct.item()/len(train_set.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 0, 0,  ..., 3, 0, 5])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preds.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stacked = torch.stack((train_set.targets, train_preds.argmax(dim=1)), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 2])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9, 9],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        ...,\n",
       "        [3, 3],\n",
       "        [0, 0],\n",
       "        [5, 5]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked # neat, pairs. [true label | predicted label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 9]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmt = torch.zeros(10,10,dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10964,    30,   110,   206,    20,    14,   578,     2,    76,     0],\n",
       "        [   24, 11802,     0,   148,     4,     0,     4,     0,    18,     0],\n",
       "        [  228,    16,  9834,   152,  1156,    14,   546,     0,    54,     0],\n",
       "        [  392,   126,    24, 11018,   274,     4,   140,     0,    22,     0],\n",
       "        [   52,    72,  1002,   568,  9700,     0,   550,     0,    56,     0],\n",
       "        [    2,     0,     0,     0,     0, 11106,     0,   690,    20,   182],\n",
       "        [ 2764,    16,  1144,   294,  1144,     8,  6478,     2,   150,     0],\n",
       "        [    0,     0,     0,     0,     0,    26,     0, 11722,     4,   248],\n",
       "        [   74,     6,    22,    32,    22,    34,    44,    24, 11742,     0],\n",
       "        [    0,     0,     0,     0,     0,    36,     0,   424,    12, 11528]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for p in stacked:\n",
    "    j,k = p.tolist()\n",
    "    cmt[j,k] += 1\n",
    "    \n",
    "cmt # nice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'resources.plotcm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-f1836e6b1a17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mresources\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotcm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'resources.plotcm'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# from resources.plotcm import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5482,   15,   55,  103,   10,    7,  289,    1,   38,    0],\n",
       "       [  12, 5901,    0,   74,    2,    0,    2,    0,    9,    0],\n",
       "       [ 114,    8, 4917,   76,  578,    7,  273,    0,   27,    0],\n",
       "       [ 196,   63,   12, 5509,  137,    2,   70,    0,   11,    0],\n",
       "       [  26,   36,  501,  284, 4850,    0,  275,    0,   28,    0],\n",
       "       [   1,    0,    0,    0,    0, 5553,    0,  345,   10,   91],\n",
       "       [1382,    8,  572,  147,  572,    4, 3239,    1,   75,    0],\n",
       "       [   0,    0,    0,    0,    0,   13,    0, 5861,    2,  124],\n",
       "       [  37,    3,   11,   16,   11,   17,   22,   12, 5871,    0],\n",
       "       [   0,    0,    0,    0,    0,   18,    0,  212,    6, 5764]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skcm = confusion_matrix(train_set.targets, train_preds.argmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Neat! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
